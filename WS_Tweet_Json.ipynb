{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...204 tweets downloaded so far\n",
      "...204 tweets downloaded so far\n",
      "Writing tweet objects to JSON please wait...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import tweepy \n",
    "import json\n",
    "\n",
    "#Twitter API credentials\n",
    "consumer_key = 'K3DfpKiRAEo7TkIAamvd0r2XJ'\n",
    "consumer_secret = '2g7O1zgpGRVk7iXkY3tYXiy5PelN4hvhKoVZW6rTL9cyN73Ujx'\n",
    "access_key = '901761485990268928-8iQnDAEJelPI9LSrdgqLlyVKuDtUKZi'\n",
    "access_secret = 'x2VQj0EBBfiUZlkqFMZ8M4XAqvgeG3eT3hvhu0QnW0rvF'\n",
    "\n",
    "\n",
    "def get_all_tweets(screen_name):\n",
    "    \n",
    "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "    \n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []    \n",
    "    \n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "    \n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        \n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "        #new_tweets = api.search(q=screen_name, count=100)\n",
    "        \n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        \n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        print(\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "        #print(alltweets)\n",
    "    #write tweet objects to JSON\n",
    "    file = open('tweet.json', 'w', encoding=\"utf8\") \n",
    "    print(\"Writing tweet objects to JSON please wait...\")\n",
    "    for status in alltweets:\n",
    "        json.dump(status._json,file,sort_keys = True,indent = 4)\n",
    "    #close the file\n",
    "    print(\"Done\")\n",
    "    file.close()\n",
    "\n",
    "if 1 == 1:\n",
    "    #pass in the username of the account you want to download\n",
    "    get_all_tweets(\"ExusiaSolutions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
